{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6d5f9b0-9f9f-4080-8fcb-488b88226eab",
   "metadata": {},
   "source": [
    "# Vanilla FL Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c88d80-a1b5-481d-ab9b-7e7a798ce3f2",
   "metadata": {},
   "source": [
    "1. Install necessary dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3e05e1b-4c9d-4611-9856-6a63ce8d8e70",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\anaconda3\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: numpy in c:\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.20.1-cp311-cp311-win_amd64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: filelock in c:\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\anaconda3\\lib\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: networkx in c:\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\anaconda3\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\anaconda3\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\anaconda3\\lib\\site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Downloading torchvision-0.20.1-cp311-cp311-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/1.6 MB 330.3 kB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.1/1.6 MB 737.3 kB/s eta 0:00:02\n",
      "   ------ --------------------------------- 0.2/1.6 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.4/1.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.5/1.6 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.7/1.6 MB 2.1 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 0.8/1.6 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.0/1.6 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.1/1.6 MB 2.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.3/1.6 MB 2.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.4/1.6 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.6/1.6 MB 2.6 MB/s eta 0:00:00\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.20.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch numpy torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05db124-79b0-47ee-9828-65c43ab651f6",
   "metadata": {},
   "source": [
    "2. Use PyTorch to define the model that will be distributed to the clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f50065a2-e873-4531-b0fa-d852f3ecf851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Example: Simple Neural Network\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 10)  # Output for 10 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)  # Flatten input\n",
    "        x = self.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f561640-6eaa-44f5-a290-31d933207ebb",
   "metadata": {},
   "source": [
    "3. Each client will train the model locally on their dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f39b8b7-bb4a-4e08-96e2-61cb0d5bb3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Load and partition dataset (e.g., MNIST)\n",
    "def load_client_data():\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "    dataset = datasets.MNIST(root=\"./data\", train=True, transform=transform, download=True)\n",
    "\n",
    "    # Split dataset into parts for clients\n",
    "    client_data = random_split(dataset, [6000] * 10)  # 10 clients with ~6000 samples each\n",
    "    return client_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dbc799-5a77-4c15-a2d4-c29422e37c18",
   "metadata": {},
   "source": [
    "4. Each client trains the model locally using their dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0039f6b-79ef-438a-bec2-9c7f7efee712",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_client(model, data_loader, epochs=1, lr=0.01):\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for inputs, labels in data_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Return the trained model parameters\n",
    "    return {name: param.data.clone() for name, param in model.state_dict().items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469bafeb-b9a3-4b78-80c1-c7f3ccb756f7",
   "metadata": {},
   "source": [
    "5. The central server aggregates updates from all clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8cab29-aca3-4bbc-bef9-2aa215970aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def federated_averaging(client_updates):\n",
    "    avg_params = {}\n",
    "    num_clients = len(client_updates)\n",
    "\n",
    "    # Average parameters across clients\n",
    "    for name in client_updates[0]:\n",
    "        avg_params[name] = sum([client[name] for client in client_updates]) / num_clients\n",
    "\n",
    "    return avg_params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46e1bc8-741c-40b4-bf3d-bd47a563dd8b",
   "metadata": {},
   "source": [
    "6. Coordinate training between the server and clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4485055-25e9-4ebd-ad52-710d227fb379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vanilla_federated_learning(num_rounds=5, num_clients=10, epochs=1):\n",
    "    # Initialize global model\n",
    "    global_model = SimpleNN()\n",
    "    client_data = load_client_data()\n",
    "\n",
    "    for round in range(num_rounds):\n",
    "        print(f\"Round {round + 1}/{num_rounds}\")\n",
    "        client_updates = []\n",
    "\n",
    "        # Each client trains the model on local data\n",
    "        for client_id in range(num_clients):\n",
    "            data_loader = DataLoader(client_data[client_id], batch_size=32, shuffle=True)\n",
    "            client_model = SimpleNN()  # Clone the global model\n",
    "            client_model.load_state_dict(global_model.state_dict())  # Sync with the global model\n",
    "            client_update = train_client(client_model, data_loader, epochs=epochs)\n",
    "            client_updates.append(client_update)\n",
    "\n",
    "        # Server aggregates updates\n",
    "        avg_params = federated_averaging(client_updates)\n",
    "\n",
    "        # Update global model\n",
    "        global_model.load_state_dict(avg_params)\n",
    "\n",
    "    print(\"Federated Learning Completed\")\n",
    "    return global_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7eb47a-6630-47a8-9675-b6417e388b42",
   "metadata": {},
   "source": [
    "7. After training, evaluate the global model on a test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bc7b69-73bc-49f3-a0b0-f09b999ca01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f3e3a8-a21c-4672-99fa-589ac96fafc1",
   "metadata": {},
   "source": [
    "8. Run the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9867a01f-54cb-42bf-ab1f-7da28a40401b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    global_model = vanilla_federated_learning()\n",
    "\n",
    "    # Load test data\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "    test_dataset = datasets.MNIST(root=\"./data\", train=False, transform=transform, download=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # Evaluate the global model\n",
    "    evaluate_model(global_model, test_loader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
